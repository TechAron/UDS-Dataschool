library(quanteda)     #Voor tokensiatie, corpora, etc.
library(topicmodels)  #Voor de topicmodels

#maken van de subset (deze versie is van september)
Newscorpus <- corpus(newspapers5)   #Corpus van de data van september (was miss al)
tok <- tokens(Newscorpus,         #tokeniseert door:
              remove_numbers = TRUE,        #nummers te verwijderen
              remove_url = TRUE,            #urls te verwijderen
              remove_symbols = TRUE,        #symbolen(?) te verwijderen
              remove_punct = TRUE) %>%      #leestekens te verwijderen
  tokens_tolower() %>%                      #alle letters kleine letters te maken
  tokens_remove(stopwords::stopwords(language = "nl"))  #en stopwoorden te verwijderen
#Woordenlijst thema migratie
TBS_tok <- tokens_select(tok,c("anne_faber$",
                               "kliniek",
                              "pompekliniek$",
                                "TBS"
                            , "tbs",
                               "enkelband",
                               "parnassia",
                               "michael_p",
                                "psychiatrisch_onderzoek",
                               "den_dolder
"), selection = "keep", padding = FALSE) #hij is een beetje aangepast. HIerdoor werd de LDA relevanter, met vaker dingen over advocaten, rechters, stoornissen et cetera. Psychiaters en ontsnappingen zijn eruit. 
newthing <- ntoken(TBS_tok) #telt het aantal voorkomens van Ã©Ã©n van de woorden op de woordenlijst per artikel
vluchtelingen_bool <- newthing > 0L #als er meer dan 0 relevante woorden in voorkomen, is het een relevant artikel
#in vluchtelingen_bool komt voor elk artikel te staan of dit het geval is

docvars(Newscorpus, "TBS") <- vluchtelingen_bool #maakt een nieuwe kolom waarin staat of het artikel relevant
#is voor het onderwerp 'tbsd'

subset_TBS <- corpus_subset(Newscorpus, TBS == TRUE) #maakt een nieuw corpus 'tbs' met alle relevante artikelen

save(subset_TBS, file = "SubsetTBS.RDATA") 
