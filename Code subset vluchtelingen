install.packages("topicmodels")

library(quanteda)     #Voor tokensiatie, corpora, etc.
library(topicmodels)  #Voor de topicmodels

vluchtelingen_corpus <- corpus(newspapers5)

vluchtelingen_corpus <- corpus(vluchtelingen_corpus)   #Corpus van de data van vluchtelingen
tok <- tokens(vluchtelingen_corpus,         #tokeniseert door:
              remove_numbers = TRUE,        #nummers te verwijderen
              remove_url = TRUE,            #urls te verwijderen
              remove_symbols = TRUE,        #symbolen(?) te verwijderen
              remove_punct = TRUE) %>%      #leestekens te verwijderen
  tokens_tolower() %>%                      #alle letters kleine letters te maken
  tokens_remove(stopwords::stopwords(language = "nl")) #en stopwoorden te verwijderen

#Woordenlijst thema migratie
migr_tok <- tokens_select(tok,c("vluchte*","asiel*","migr*","ter_apel","azc", "jungle_van_calais"), selection = "keep", padding = FALSE)
newthing <- ntoken(migr_tok) #telt het aantal voorkomens van één van de woorden op de woordenlijst per artikel
vluchtelingen_bool <- newthing > 1L #als er meer dan 1 relevante woorden in voorkomen, is het een relevant artikel
#in vluchtelingen_bool komt voor elk artikel te staan of dit het geval is

vlucht_C <- vluchtelingen_corpus #slaat het corpus opnieuw op voor het geval we het corpus per ongeluk slopen

docvars(vlucht_C, "vluchtelingen") <- vluchtelingen_bool #maakt een nieuwe kolom waarin staat of het artikel relevant
#is voor het onderwerp 'vluchtelingen'

vlucht_volledig <- corpus_subset(vlucht_C, vluchtelingen == TRUE) #maakt een nieuw corpus 'vlucht_volledig' met alle relevante artikelen

print("vluchtelingen_corpus")

save(vlucht_volledig, file = "vluchtelingenvolledig_corpus")
