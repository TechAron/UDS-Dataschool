---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---
```{r eval = FALSE}
library(lda)
library(magrittr)
library(stopwords)
library(quanteda)
september1 <- corpus(september)
CompVec <- c("Theresa May", "Den Haag", "Europese Unie") 
RemVec <- c("zag", "liet", "zat", "vertelt", "kun") 

TokSep <- tokens(september1, remove_numbers = TRUE, remove_punct = TRUE, remove_sep = TRUE, remove_url = TRUE) %>% 
  tokens_compound(CompVec) %>%
  tokens_tolower() %>% 
  tokens_remove(stopwords::stopwords(language = "nl")) %>%
  tokens_remove(stopwords::stopwords(language = "en")) %>% #blijkbaar staat er nog al eens 'the' in de documenten, die moet er ook uit 
  tokens_remove(RemVec) 
```
```{r eval = FALSE}
TokMat <- dfm(TokSep) #een dataframe maken 
TokMat
TokMatTrim <- dfm_trim(TokMat, min_docfreq = 0.001, max_docfreq = 0.01, docfreq_type = "prop") #  features trimmen: hoge sparsity, hoog aantal features zodat de LDA het meeste zin heeft
TokMatTrim
```
```{r eval = FALSE}
TokMatTLDA <- 
  LDA(convert(TokMatTrim, to = "topicmodels"), k=10) 
get_terms(TokMatTLDA, 5) #zo kies ik een topic. Met deze code (runtime +- 40 minuten) komen verschillende interessante onderwerpen naar boven die met elkaar te maken hebben
```

```{r eval = FALSE}
docvars(september1)
```
